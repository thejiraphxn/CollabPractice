{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1bt0_8d2XUL8LQgWzdFfCrlB3frW9dlEC","authorship_tag":"ABX9TyMiXQ8tMfiuaQCaD3I5M8Hy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsyDLWh20rSz","executionInfo":{"status":"ok","timestamp":1711692795702,"user_tz":-420,"elapsed":8,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"518ed74a-84a0-4fef-8c70-6feac746162a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]}],"source":["%tensorflow_version 2.x\n"]},{"cell_type":"code","source":["!pip install pythainlp\n","!pip install epitran\n","!pip install sklearn_crfsite\n","!pip install attacut\n","!pip install tensorflow deepcut"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fi4q2qnY1556","executionInfo":{"status":"ok","timestamp":1711693151092,"user_tz":-420,"elapsed":138604,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"c14b557d-54f4-4924-f48a-1af3d23dfada"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pythainlp\n","  Using cached pythainlp-5.0.1-py3-none-any.whl (17.9 MB)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.2.2)\n","Installing collected packages: pythainlp\n","Successfully installed pythainlp-5.0.1\n","Collecting epitran\n","  Using cached epitran-1.25-py2.py3-none-any.whl (173 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from epitran) (67.7.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from epitran) (2023.12.25)\n","Collecting panphon>=0.20 (from epitran)\n","  Using cached panphon-0.20.0-py2.py3-none-any.whl (73 kB)\n","Collecting marisa-trie (from epitran)\n","  Using cached marisa_trie-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from epitran) (2.31.0)\n","Collecting unicodecsv (from panphon>=0.20->epitran)\n","  Using cached unicodecsv-0.14.1-py3-none-any.whl\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (6.0.1)\n","Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (1.25.2)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (0.6.2)\n","Collecting munkres (from panphon>=0.20->epitran)\n","  Using cached munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2024.2.2)\n","Installing collected packages: unicodecsv, munkres, panphon, marisa-trie, epitran\n","Successfully installed epitran-1.25 marisa-trie-1.1.0 munkres-1.1.4 panphon-0.20.0 unicodecsv-0.14.1\n","\u001b[31mERROR: Could not find a version that satisfies the requirement sklearn_crfsite (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for sklearn_crfsite\u001b[0m\u001b[31m\n","\u001b[0mCollecting attacut\n","  Downloading attacut-1.0.6-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docopt>=0.6.2 (from attacut)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting fire>=0.1.3 (from attacut)\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting nptyping>=0.2.0 (from attacut)\n","  Downloading nptyping-2.5.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (1.25.2)\n","Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.10/dist-packages (from attacut) (6.0.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (1.16.0)\n","Collecting ssg>=0.0.4 (from attacut)\n","  Downloading ssg-0.0.8-py3-none-any.whl (473 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (2.2.1+cu121)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.1.3->attacut) (2.4.0)\n","Collecting python-crfsuite>=0.9.6 (from ssg>=0.0.4->attacut)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from ssg>=0.0.4->attacut) (4.66.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m992.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.2.0->attacut)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.2.0->attacut)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2.0->attacut) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2.0->attacut) (1.3.0)\n","Building wheels for collected packages: docopt, fire\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d03d1c4250ac250c1cb68c66cb4e2db177fe69cee48b54c061f71957bf4fa840\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=d579e369bc36f40c50a92e9f0b3cbb87467174a062b15f28d3671e48ebcb7729\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built docopt fire\n","Installing collected packages: python-crfsuite, docopt, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, fire, ssg, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, attacut\n","Successfully installed attacut-1.0.6 docopt-0.6.2 fire-0.6.0 nptyping-2.5.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 python-crfsuite-0.9.10 ssg-0.0.8\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: deepcut in /usr/local/lib/python3.10/dist-packages (0.7.0.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepcut) (1.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deepcut) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepcut) (1.2.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepcut) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepcut) (2023.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepcut) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepcut) (3.4.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["import pythainlp\n","from pythainlp import sent_tokenize, word_tokenize\n","\n","text = \"งานวิจัยในครั้งนี้มีจุฬาลงกรณ์มหาวิทยาลัย ที่เป็นสถาบันการศึกษาที่แข็งแกร่งทางด้านภาษาศาสตร์และคอมพิวเตอร์ รวมถึง NECTEC สถาบันวิจัยด้านเทคโนโลยีที่เชี่ยวชาญด้านปัญญาประดิษฐ์(AI)มาตลอด 30 ปี และธนาคารกสิกรไทยผู้นำด้านธุรกิจการเงินการธนาคารที่พร้อมสนับสนุน ข้อมูลเพื่อให้งานวิจัยออกมาใช้ได้จริงกับภาคธุรกิจ เกิดเป็นความสำเร็จในการพัฒนา Thai NLP ครั้งนี้ \"\n","\n","sentent = sent_tokenize(text, engine=\"whitespace+newline\")\n","print(sentent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoESoS-r3aan","executionInfo":{"status":"ok","timestamp":1711693722618,"user_tz":-420,"elapsed":517,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"4bfd880c-c0d5-4641-a2ad-6868aaaafa9d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['ควยไอ้สัสเอ้ยมีแต่ปัญหา', 'อยากแปลงร่างเป็นพญานาค']\n"]}]},{"cell_type":"code","source":["word1 = word_tokenize(text)\n","word2 = word_tokenize(text, keep_whitespace=False)\n","print(\"Space count\", word1)\n","print(\"Ignore to count space\", word2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeO_p_ih49rR","executionInfo":{"status":"ok","timestamp":1711693726868,"user_tz":-420,"elapsed":359,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"dafc13da-7cb7-4f59-f5bc-b927d29286b2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Space count ['ควย', 'ไอ้', 'สัส', 'เอ้ย', 'มี', 'แต่', 'ปัญหา', ' ', 'อยาก', 'แปลงร่าง', 'เป็น', 'พญานาค']\n","Ignore to count space ['ควย', 'ไอ้', 'สัส', 'เอ้ย', 'มี', 'แต่', 'ปัญหา', 'อยาก', 'แปลงร่าง', 'เป็น', 'พญานาค']\n"]}]},{"cell_type":"code","source":["for x in word2:\n","  print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1q4fg1U5muy","executionInfo":{"status":"ok","timestamp":1711693811548,"user_tz":-420,"elapsed":342,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"b2f9eb23-9de3-4b5c-b355-664ef961ce9a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ควย\n","ไอ้\n","สัส\n","เอ้ย\n","มี\n","แต่\n","ปัญหา\n","อยาก\n","แปลงร่าง\n","เป็น\n","พญานาค\n"]}]},{"cell_type":"code","source":["from pythainlp import subword_tokenize\n","subword_tokenize(text, engine=\"ssg\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXsm7f_R5u43","executionInfo":{"status":"ok","timestamp":1711693901066,"user_tz":-420,"elapsed":336,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"079c1631-7f4b-4321-a141-d4f8b2bb6b0b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ควย',\n"," 'ไอ้',\n"," 'สัส',\n"," 'เอ้ย',\n"," 'มี',\n"," 'แต่',\n"," 'ปัญ',\n"," 'หา ',\n"," 'อยาก',\n"," 'แปลง',\n"," 'ร่าง',\n"," 'เป็น',\n"," 'พญา',\n"," 'นาค']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["myfile = open(\"/content/drive/MyDrive/CPE270/textT.txt\")\n","txt = myfile.read()\n","txt = txt.replace(\" \", \"\")\n","print(txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6u9Fbp-l6fPx","executionInfo":{"status":"ok","timestamp":1711694296327,"user_tz":-420,"elapsed":4,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"9f9e7d3e-b541-404d-b35c-c0087ba230a6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["เหตุผลหลักๆก็ด้วยปัจจัยของโครงสร้างทางภาษาที่ซับซ้อนกว่าภาษาอังกฤษทั้งสระวรรณยุกต์คำๆเดียวอ่านได้หลายรูปแบบมีรูปแบบประโยคที่เขียนติดกันหมด\n","หากลองสลับคำนิดหน่อยความหมายก็เปลี่ยนได้อีกเช่นคำว่า“ขอบอก”อ่านได้ทั้งขอ-บอกและขอบ-อกหรือประโยคที่ว่า“คนขับรถไปตั้งแต่เช้า”\n","มีความหมายทั้ง“คน-ขับรถ-ไปตั้งแต่เช้า”หรือ“คนขับรถ-ไปตั้งแต่เช้า”เป็นต้น\n","\n","แล้วยิ่งถ้าเป็นภาษาแชทที่ใช้กันปกติในอินเตอร์เน็ตนั้นบ้านเราก็มีคำวิจิตรพิศดารใหม่ๆให้ใช้เพิ่มขึ้นทุกวันจึงเป็นเรื่องยากที่คอมพิวเตอร์จะเข้าใจภาษาไทยเราได้ง่ายๆ\n","ซึ่งถ้าหากเราพัฒนาเรื่องนี้ได้ดีเท่าไหร่โอกาสเติบโตของวงการเทคโนโลยีบ้านเราก็จะไปได้ไกลมากขึ้นเท่านั้น\n","\n","ด้วยเหตุผลนี้เองธนาคารกสิกรไทยจึงได้จับมือกับจุฬาลงกรณ์มหาวิทยาลัยศูนย์เทคโนโลยีอิเลคทรอนิกส์และคอมพิวเตอร์แห่งชาติ(NECTEC)\n","และบริษัทกสิกรไทยบิซิเนส-เทคโนโลยีกรุ๊ป(KBTG)พัฒนานวัตกรรมการประมวลผลภาษาไทยเรียกว่าThaiNLPในส่วนของภาษาทางการเงินธนาคารและธุรกิจ\n","\n","งานวิจัยในครั้งนี้มีจุฬาลงกรณ์มหาวิทยาลัยที่เป็นสถาบันการศึกษาที่แข็งแกร่งทางด้านภาษาศาสตร์และคอมพิวเตอร์รวมถึงNECTEC\n","สถาบันวิจัยด้านเทคโนโลยีที่เชี่ยวชาญด้านปัญญาประดิษฐ์(AI)มาตลอด30ปีและธนาคารกสิกรไทยผู้นำด้านธุรกิจการเงินการธนาคารที่พร้อมสนับสนุน\n","ข้อมูลเพื่อให้งานวิจัยออกมาใช้ได้จริงกับภาคธุรกิจเกิดเป็นความสำเร็จในการพัฒนาThaiNLPครั้งนี้\n"]}]},{"cell_type":"code","source":["text = str(input())\n","rude_words = [\"มึง\", \"ไอ้\", \"เอ็ง\"]\n","polite_words = \"คุณ\"\n","rude_word_output = 0\n","\n","for i in word_tokenize(text, keep_whitespace=False):\n","  if i in rude_words:\n","    rude_word_output = rude_word_output + 1\n","\n","for rude_word in rude_words:\n","  text = text.replace(rude_word, polite_words)\n","\n","print(text)\n","print(output2)\n","print(\"คำหยาบ\", rude_word_output)\n","print(\"คำทั้งหมด\", len(word_tokenize(text, keep_whitespace=False)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7Qg7afB7lNU","executionInfo":{"status":"ok","timestamp":1711696030722,"user_tz":-420,"elapsed":7136,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"66c2f0ca-d9dd-4a0b-d519-bd87e54cc3ab"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["มึงมึงไอ้เอ็ง\n","คุณคุณคุณคุณ\n","2\n","คำหยาบ 4\n","คำทั้งหมด 4\n"]}]},{"cell_type":"code","source":["from pythainlp.tag import pos_tag, pos_tag_sents\n","pos_tag([\"การ\", \"เดินทาง\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfigQNCtAWvK","executionInfo":{"status":"ok","timestamp":1711695624883,"user_tz":-420,"elapsed":873,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"6951783a-4940-45f3-e78b-aed8c514c4b3"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('การ', 'FIXN'), ('เดินทาง', 'VACT')]"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["word = [\"ชาวต่างชาติ\", \"เรียก\", \"อาณาจักร\", \"อยุธยา\", \"ว่า\", \"สยาม\"]\n","pos_tag(word)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4wXLSSgApeg","executionInfo":{"status":"ok","timestamp":1711695897620,"user_tz":-420,"elapsed":474,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"d45b9d4b-6532-4d1b-c6bd-e496b693d5b4"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ชาวต่างชาติ', 'NCMN'),\n"," ('เรียก', 'VACT'),\n"," ('อาณาจักร', 'NCMN'),\n"," ('อยุธยา', 'VACT'),\n"," ('ว่า', 'JSBR'),\n"," ('สยาม', 'NCMN')]"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["pos_tag(word, corpus=\"pud\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5FvhNOMBpID","executionInfo":{"status":"ok","timestamp":1711695895607,"user_tz":-420,"elapsed":329,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}},"outputId":"13b002e6-e29d-4154-a681-7efb1c7935a8"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ชาวต่างชาติ', 'NOUN'),\n"," ('เรียก', 'VERB'),\n"," ('อาณาจักร', 'VERB'),\n"," ('อยุธยา', 'VERB'),\n"," ('ว่า', 'ADP'),\n"," ('สยาม', 'NOUN')]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["import pandas as pd\n","data_pt = pd.DataFrame(pos_tag(word))\n","data_pt.to_csv(\"/content/drive/MyDrive/data_pt.csv\")"],"metadata":{"id":"uDzK3OtlBv9p","executionInfo":{"status":"ok","timestamp":1711696165314,"user_tz":-420,"elapsed":344,"user":{"displayName":"5911 จิรพนธ์ เอี้ยวตระกูล","userId":"08721191241649546443"}}},"execution_count":53,"outputs":[]}]}